---
title: "Air quality report - data exploration"
format: 
    html:
        #eval: false
        code-fold: true
        code-overflow: scroll
---

## Introduction

This is an exploratory analysis of air quality reports for Catalonia region, updated as of 02/05/2025. 
Data is downloaded from the [open data portal](https://administraciodigital.gencat.cat/ca/dades/dades-obertes/inici/index.html#googtrans(ca|en)) 
of Catalan Government (Generalitat de Catalunya), and includes hourly air quality metrics as well as 
geospatial information of the capture points.

The objective of this analysis is to find the biggest contributors to air pollution.

```{python}
py_ver = !python --version
print(f"Python version (virtual environment):{py_ver[0]}\n\n")

!kedro -V
```

## Project workflow

The analysis is structured around a [kedro](https://docs.kedro.org/en/stable/introduction/index.html) 
basic workflow, written in Python and uses the following packages:

- uv (package dependency manager)
- quarto (report renderer)
- pandas (data wrangling)
- altair (data visualization)
- geopandas (geospatial analysis)

WIP

## Data structure

The raw data is a unique CSV file with the following columns:

```{python}
from kedro.io import DataCatalog
import pandas as pd
import yaml

with open("../conf/base/catalog.yml", "r") as f:
    conf_catalog = yaml.safe_load(f)

catalog = DataCatalog.from_config(conf_catalog)
pd_raw = catalog.load("air_quality_log")
```

```{python}
pd_raw.info()
```

The contained data can be divided in the following content types:

- Identification: columns 0, 1
- Time: column 2 (and partially columns 12-35)
- Location: columns 7, 8?, 9, 10, 11, 36, 37, 38, 39
- Technical station info: column 6
- Measurement info: columns 3, 4, 5, 12-35

Data structure doesn't follow a strict "row per measurement" lemma, 
as every row of the file contains 24 data measurements (hourly average per each day).
Also there seems to be stations that capture different air parameters at the same time,
but in the original data each parameter is written in a different line.

Some rework will have to be done for easier anaylisis, pivoting the data in order to have
one row for each time measurement (per station), with as many columns as different air parameters are.

```{python}
print(f"Different air parameters or contaminants: {pd_raw.loc[:,"CONTAMINANT"].nunique()}")
pd_raw.loc[:,"CONTAMINANT"].unique()
```

Data types seem apropiate to the content. Once pivoted, however, new data types will have to be added, 
such as timestamp for the combined date + hour information. The geographic information, which is plain text or floats,
will have to be converted for geospatial analysis. This will be done by converting the whole data type from a pandas
normal DataFrame to a geopandas GeoDataFrame (which will retain all of its previous columns plus a 'geometry' column).